{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed415ece-3ded-486a-9d90-1e504888950a",
   "metadata": {},
   "source": [
    "# Synchrone Verteilung Worker1\n",
    "Die Konfiguration von den Folgenden Workern ist nahezu identisch. Der einzige Unterschied besteht in der Clusterkonfiguration. Der Vollständigkeit halber wird hier sämtlicher benötigter Code gezeigt, jedoch nicht näher erleutert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4d3257-0b9c-41a1-8d61-659bc2fe7c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d24014e-996d-49b1-bea0-db5019941406",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Clusterkonfiguration\n",
    "Die Clusterkonfiguration der Worker muss als näcshtes Stattfinden. Dabei werden alle Teilnehmer in die os.environ Umgebungsvariablegeschrieben werden.\n",
    "Dann können wir die Distribution Strategie bestimmen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c3a38a-1f21-4aa1-98d6-d2a24ce1cd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CONFIG'] = json.dumps({\n",
    "    'cluster': {\n",
    "        'worker': ['192.168.2.1:12345', '192.168.2.1:12345', '192.168.2.3:12345'] #hier werden ip's und ports der teilnehmenden devices angegeben\n",
    "    },\n",
    "    'task': {'type': 'worker', 'index': 0} # hier wird die eigene rolle und index angegeben. Da wir hier den index 0 haben wird dieses device zum chief\n",
    "})\n",
    "\n",
    "strategy = tf.distribute.MultiWorkerMirroredStrategy() # MultiWorkerMirroredStrategy zum Synchronen lernen auf 3 devices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beebd53a-eeec-4e39-98d1-4c6da9b30f1c",
   "metadata": {},
   "source": [
    "## Vorbereitung der Trainingsdaten\n",
    "In diesem Abschnitt werden die trainings und Testen Daten vorbereitet. In diesem Fall wird beispielhaft der MNist Datensatz heruntergeladen und zu einem tensorflow dataset gemacht.\n",
    "Zur späteren Verwendung kann man besagten TensorFlow Dataset oder aber auch ein numpy array verwenden.\n",
    "Die Batchsize ist hierbei pro Worker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ae76d4-e1a0-4371-9db0-bf0a8bc0bee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=10000).batch(64)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0014b22d-401b-42a6-8cfa-a76fb485768d",
   "metadata": {},
   "source": [
    "## Modelerstellung\n",
    "Nun kann man sein Modell erstellen. In diesem Beispiel wird ein einfaches NN mit einer hidden Layer erstellt. Zu beachten ist, dass das Model innerhalb von strategy.scope() erstellt und compiled werden musst. \n",
    "Zusätzlich müssen die Models auf den verschiedenen Worker natürlich identisch sein um keinen Error zu Produzieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57acbf2f-b36a-4936-b2e4-753a4099af11",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    distributed_model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "   \n",
    "    distributed_model.compile(loss='sparse_categorical_crossentropy',\n",
    "                  optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbefea97-41f3-479b-a52b-c34d630572e3",
   "metadata": {},
   "source": [
    "## Das Modell trainieren\n",
    "Zum schluss wird mittels model.fit das erstellte Modell trainiert. Hierbei kann man wie üblich zusätzlich parameter wie z.B. Callbacks oder ein Validation Dataset angeben. \n",
    "Nachdem man dies auf allen Workern ausgeführt hat beginnt der Synchrone Trainingsprozess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1306f44-a46c-4e90-86e7-97006a056a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "distributed_model.fit(train_dataset, epochs=10, steps_per_epoch=20, validation_data=val_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
